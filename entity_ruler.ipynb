{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting Entities and Creating Entity Ruler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U spacy\n",
    "# python -m spacy download en_core_web_sm\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import ssl\n",
    "import utils\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting Entities\n",
    "\n",
    "## Programming Languages (Wikipedia)\n",
    "\n",
    "[List of programming languages](https://en.wikipedia.org/wiki/List_of_programming_languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper\n",
    "\n",
    "def text_cleaner(text: str) -> str:\n",
    "    text = text.encode(\"ascii\", \"ignore\")\n",
    "    return text.decode().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_programming_languages'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "data = []\n",
    "for lang in soup.select('.div-col > ul > li'):\n",
    "    data.append([lang.text.strip()])\n",
    "utils.save_csv(path='data/languages.csv', columns=['name'], rows=data)\n",
    "data[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Platforms (Cloud Service Providers From Wikipedia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://en.wikipedia.org'\n",
    "url = f'{base_url}/wiki/Category:Cloud_platforms'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "data = []\n",
    "container = soup.find(attrs={'class': 'mw-category-generated'})\n",
    "for x in container.select('ul > li'):\n",
    "    data.append([text_cleaner(x.text)])\n",
    "\n",
    "sub_categories = soup.find(attrs={'id': 'mw-subcategories'})\n",
    "for anchor in sub_categories.find_all('a'):\n",
    "    href = anchor.get(\"href\")\n",
    "    url = f'{base_url}{href}'\n",
    "    response = requests.get(url)\n",
    "    # print(response.url)\n",
    "    _soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    _container = _soup.find(attrs={'class': 'mw-category-generated'})\n",
    "    for x in _container.select('ul > li'):\n",
    "        data.append([text_cleaner(x.text)])\n",
    "\n",
    "utils.save_csv(path='data/platforms.csv', columns=['name'], rows=data)\n",
    "data[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Databases\n",
    "\n",
    "* [Data Store](https://en.wikipedia.org/wiki/Data_store)\n",
    "    * [Relational Database](https://en.wikipedia.org/wiki/Relational_database)\n",
    "    * [Graph Database](https://en.wikipedia.org/wiki/Graph_database)\n",
    "    * [Wide Column Store](https://en.wikipedia.org/wiki/Wide-column_store)\n",
    "    * [NoSQL](https://en.wikipedia.org/wiki/NoSQL)\n",
    "    * [Key-Value Database](https://en.wikipedia.org/wiki/Key%E2%80%93value_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "# Relational Databases\n",
    "url = 'https://en.wikipedia.org/wiki/Relational_database#Relational_model'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "data = []\n",
    "container = soup.select_one(\"#mw-content-text > div.mw-parser-output > ol:nth-child(89)\")\n",
    "for x in container.find_all('li'):\n",
    "    data.append([text_cleaner(x.text)])\n",
    "\n",
    "# Graph Databases\n",
    "df = pd.read_html(\"https://en.wikipedia.org/wiki/Graph_database\", attrs={\"class\": \"wikitable\"})[0]\n",
    "for x in df['Name'].tolist():\n",
    "    data.append([text_cleaner(x)])\n",
    "\n",
    "# Wide Column Store\n",
    "url = 'https://en.wikipedia.org/wiki/Wide-column_store'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "container = soup.select_one(\"#mw-content-text > div.mw-parser-output > ul\")\n",
    "for x in container.find_all('li'):\n",
    "    data.append([text_cleaner(x.text)])\n",
    "\n",
    "# NoSQL\n",
    "df = pd.read_html(\"https://en.wikipedia.org/wiki/NoSQL\")\n",
    "for x in df[0]['Notable examples of this type'].tolist():\n",
    "    for y in str(x).split(','):\n",
    "        data.append([text_cleaner(y)])\n",
    "\n",
    "for x in df[1]['Name'].tolist():\n",
    "    data.append([text_cleaner(x)])\n",
    "\n",
    "for x in df[3]['Database'].tolist():\n",
    "    data.append([text_cleaner(x)])\n",
    "\n",
    "# Key-Value Databases\n",
    "df = pd.read_html(\"https://en.wikipedia.org/wiki/Key%E2%80%93value_database\")[1]\n",
    "for x in df['Provider'].tolist():\n",
    "    data.append([text_cleaner(x)])\n",
    "\n",
    "\n",
    "utils.save_csv(path='data/databases.csv', columns=['name'], rows=data)\n",
    "data[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frameworks & Tools\n",
    "\n",
    "Data was manually typed from various tech blog such as medium.com etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Entity Ruler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = pd.read_csv('data/languages.csv')\n",
    "platforms = pd.read_csv('data/platforms.csv')\n",
    "databases = pd.read_csv('data/databases.csv')\n",
    "frameworks_tools = pd.read_csv('data/frameworks_tools_etc.csv')\n",
    "\n",
    "patterns = []\n",
    "for x in languages.name.tolist():\n",
    "    patterns.append({\"label\": \"PROG_LANG\", \"pattern\": x, \"id\": \"SKILLS\"})\n",
    "\n",
    "for x in databases.name.tolist():\n",
    "    patterns.append({\"label\": \"DB\", \"pattern\": [{\"lower\": w.lower()} for w in str(x).split()], \"id\": \"SKILLS\"})\n",
    "\n",
    "for x in platforms.name.tolist():\n",
    "    patterns.append({\"label\": \"PLATFORM\", \"pattern\": [{\"lower\": w.lower()} for w in str(x).split()], \"id\": \"SKILLS\"})\n",
    "\n",
    "for x in frameworks_tools.name.tolist():\n",
    "    patterns.append({\"label\": \"FRAMEWORKS\", \"pattern\": [{\"lower\": w.lower()} for w in str(x).split()], \"id\": \"SKILLS\"})\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
    "ruler.add_patterns(patterns)\n",
    "ruler.to_disk(\"data/patterns.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f0a3f423196cf0c7751f864a73e86be27a2d2c930834ca9d6f043880c790807f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
